{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み込みと前処理を行うためのnotebookです。  \n",
    "モデルの学習と予測にはここで処理をかけたデータを利用するようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize(df):\n",
    "    \"\"\"\n",
    "    指定された列を二値化する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        二値化対象のデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        二値化されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y': 1, 'N': 0})\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data(input_file):\n",
    "    \"\"\"\n",
    "    指定されたファイルからデータを読み込み、前処理を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        読み込むデータファイルのパス。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        前処理されたデータフレーム。\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (pd.Timestamp('2018-02-01') - df['first_active_month']).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data('../data/raw/train.csv')\n",
    "test = read_data('../data/raw/test.csv')\n",
    "\n",
    "new_transactions = pd.read_csv('../data/raw/new_merchant_transactions.csv',\n",
    "                               parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/raw/historical_transactions.csv',\n",
    "                                      parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_month_diff(transactions):\n",
    "    \"\"\"\n",
    "    purchase_dateとmonth_lagを基にmonth_diffを計算する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        month_diff列が追加されたデータフレーム。\n",
    "    \"\"\"\n",
    "    current_date = pd.Timestamp(datetime.datetime.today())\n",
    "    transactions['month_diff'] = ((current_date - transactions['purchase_date']).dt.days) // 30\n",
    "    transactions['month_diff'] += transactions['month_lag']\n",
    "    return transactions\n",
    "\n",
    "\n",
    "def encode_categorical_columns(df, columns):\n",
    "    \"\"\"\n",
    "    指定されたカテゴリカル列をワンホットエンコーディングする。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        エンコード対象のデータフレーム。\n",
    "    columns : list of str\n",
    "        エンコードするカテゴリカル列のリスト。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        ワンホットエンコードされたデータフレーム。\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=columns)\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_transactions(history):\n",
    "    \"\"\"\n",
    "    取引データを集計する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).astype(np.int64) * 1e-9\n",
    "    \n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean'],\n",
    "        'category_2_2.0': ['mean'],\n",
    "        'category_2_3.0': ['mean'],\n",
    "        'category_2_4.0': ['mean'],\n",
    "        'category_2_5.0': ['mean'],\n",
    "        'category_3_A': ['mean'],\n",
    "        'category_3_B': ['mean'],\n",
    "        'category_3_C': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['mean', 'max', 'min', 'std'],\n",
    "        'month_diff': ['mean']\n",
    "    }\n",
    "    \n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "    \n",
    "    return agg_history\n",
    "\n",
    "\n",
    "def aggregate_per_month(history):\n",
    "    \"\"\"\n",
    "    月ごとの取引データを集計する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        月ごとに集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "        'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "        'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "    }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "    \n",
    "    return final_group\n",
    "\n",
    "\n",
    "def successive_aggregates(df, field1, field2):\n",
    "    \"\"\"\n",
    "    指定されたフィールドを基に連続集計を行う。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    field1 : str\n",
    "        集計の基準となるフィールド。\n",
    "    field2 : str\n",
    "        集計されるフィールド。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        連続集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    t = df.groupby(['card_id', field1])[field2].mean()\n",
    "    u = pd.DataFrame(t).reset_index().groupby('card_id')[field2].agg(['mean', 'min', 'max', 'std'])\n",
    "    u.columns = [field1 + '_' + field2 + '_' + col for col in u.columns.values]\n",
    "    u.reset_index(inplace=True)\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1332.66 Mb (57.1% reduction)\n",
      "Mem. usage decreased to 86.12 Mb (58.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n",
    "\n",
    "# 月の差を計算\n",
    "historical_transactions = calculate_month_diff(historical_transactions)\n",
    "new_transactions = calculate_month_diff(new_transactions)\n",
    "\n",
    "# カテゴリカル列をワンホットエンコーディング\n",
    "historical_transactions = encode_categorical_columns(historical_transactions, ['category_2', 'category_3'])\n",
    "new_transactions = encode_categorical_columns(new_transactions, ['category_2', 'category_3'])\n",
    "\n",
    "# メモリ使用量の削減\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)\n",
    "\n",
    "# authorized_flagの平均を計算\n",
    "agg_fun = {'authorized_flag': ['mean']}\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "# authorized_flagに基づいてデータを分割\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n",
    "\n",
    "# purchase_month列を追加\n",
    "historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n",
    "authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n",
    "new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month\n",
    "\n",
    "# データの集計\n",
    "history = aggregate_transactions(historical_transactions)\n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "\n",
    "authorized = aggregate_transactions(authorized_transactions)\n",
    "authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n",
    "\n",
    "new = aggregate_transactions(new_transactions)\n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "\n",
    "# 月ごとのデータの集計\n",
    "final_group = aggregate_per_month(authorized_transactions)\n",
    "\n",
    "# 連続集計\n",
    "additional_fields = successive_aggregates(new_transactions, 'category_1', 'purchase_amount')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'installments', 'purchase_amount'), on='card_id', how='left')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'city_id', 'purchase_amount'), on='card_id', how='left')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'category_1', 'installments'), on='card_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, authorized, on='card_id', how='left')\n",
    "test = pd.merge(test, authorized, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, final_group, on='card_id', how='left')\n",
    "test = pd.merge(test, final_group, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, additional_fields, on='card_id', how='left')\n",
    "test = pd.merge(test, additional_fields, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理終了後のデータの保存\n",
    "- 基本的にモデルの学習・ハイパーパラメータチューニングを行う際にはここで作成した同じデータを使い回して下さい。\n",
    "- 適宜前処理を変更した場合はファイル名を変えるなどして管理して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240614_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240614_test.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = read_data('../data/processed/processed20240614_train.csv')\n",
    "test = read_data('../data/processed/processed20240614_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transactions = pd.read_csv('../data/raw/new_merchant_transactions.csv',\n",
    "                                parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/raw/historical_transactions.csv',\n",
    "                                      parse_dates=['purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 追加の特徴量[1]\n",
    "# authorized_flag=0だけでmonth_diffの平均を取る\n",
    "# authorized_flag=0のフィルターを作成\n",
    "filter_authorized = historical_transactions[historical_transactions['authorized_flag'] == \"N\"].copy()\n",
    "# 現在の日時を取得\n",
    "current_date = pd.Timestamp(datetime.datetime.today())\n",
    "filter_authorized['purchase_date'] = pd.to_datetime(filter_authorized['purchase_date'])\n",
    "\n",
    "# 月差分（month_diff）を計算し、新しい列として追加\n",
    "filter_authorized['fil0_month_diff'] = (((current_date - filter_authorized['purchase_date']).dt.days) // 30).astype('int32')\n",
    "\n",
    "# 月の異常な取引を算出\n",
    "filter_authorized['fil0_month_diff'] += filter_authorized['month_lag']\n",
    "# card_idごとにmonth_diffの平均値をとる\n",
    "month_diff_mean = filter_authorized.groupby('card_id')['fil0_month_diff'].agg(['mean', 'min', 'max']).astype('float32').reset_index()\n",
    "month_diff = month_diff_mean.rename(columns={\n",
    "    'mean': 'fill0_month_diff_mean',\n",
    "    'min': 'fill0_month_diff_min',\n",
    "    'max': 'fill0_month_dfll_max'\n",
    "}).reset_index()\n",
    "# month_diff.head()\n",
    "\n",
    "# 追加の特徴量[2]\n",
    "# 最後に購入した日の購入額\n",
    "# 最後に購入した日\n",
    "last_purchase_date = historical_transactions.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "\n",
    "# 最終購入日の金額を取得する\n",
    "merge_last_purchase = pd.merge(last_purchase_date, historical_transactions[['card_id', 'purchase_date', 'purchase_amount']], on=['card_id', 'purchase_date'], how='inner')\n",
    "\n",
    "# card_id, purchase_dateごとのpurchase_amountの最大値、最小値、中央値、平均値を算出する。\n",
    "merge_last_purchase_agg = merge_last_purchase.groupby(['card_id', 'purchase_date'])['purchase_amount'].agg(['mean', 'min', 'max']).astype('float32').reset_index()\n",
    "\n",
    "# カラム名を変更する\n",
    "re_last_purchase = merge_last_purchase_agg.rename(columns={\n",
    "    'mean': 'last_purchase_amount_mean',\n",
    "    'min': 'last_purchase_amount_min',\n",
    "    'max': 'last_purchase_amount_max'\n",
    "}).reset_index()\n",
    "df_last_purchase = re_last_purchase[['card_id', 'last_purchase_amount_mean', 'last_purchase_amount_min', 'last_purchase_amount_max']]\n",
    "\n",
    "# 追加の特徴量[3]\n",
    "# 一番取引額が多い\n",
    "max_amount = historical_transactions.groupby('card_id').agg({'purchase_amount': 'max'}).astype('float32').reset_index()\n",
    "max_amount.rename(columns={'purchase_amount': 'max_purchase_amount'}, inplace=True)\n",
    "\n",
    "# 追加の特徴量[4]\n",
    "# 最高購入金額 - 最小購入金額\n",
    "amount_diff = historical_transactions.groupby('card_id')['purchase_amount'].agg({'max', 'min'}).reset_index()\n",
    "amount_diff['max_min_amount_dff'] = amount_diff['max'] - amount_diff['min']\n",
    "diff_amount = amount_diff[['card_id', 'max_min_amount_dff']]\n",
    "\n",
    "# 追加の特徴量[5]\n",
    "# purchase_date を日付型に変換\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "\n",
    "# 今日の日付を取得\n",
    "current_date = pd.Timestamp(datetime.datetime.today())\n",
    "\n",
    "# first_last_dates を作成\n",
    "first_last_dates = historical_transactions.groupby('card_id').agg({\n",
    "    'purchase_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# 取引期間を計算\n",
    "first_last_dates.columns = ['card_id', 'first_purchase_date', 'last_purchase_date']\n",
    "first_last_dates['transaction_days'] = (first_last_dates['last_purchase_date'] - first_last_dates['first_purchase_date']).dt.days\n",
    "\n",
    "# month_lag はそのまま使う\n",
    "df_his = historical_transactions[['card_id', 'purchase_date', 'month_lag']]\n",
    "\n",
    "# 不要な列を削除\n",
    "del historical_transactions\n",
    "\n",
    "# 月差分（month_diff）を計算し、新しい列として追加\n",
    "df_his['month_diff'] = (((current_date - df_his['purchase_date']).dt.days) // 30).astype('int16')\n",
    "df_his['month_diff'] += df_his['month_lag']\n",
    "\n",
    "# 不要な列を削除\n",
    "df_his.drop(columns=['purchase_date', 'month_lag'], inplace=True)\n",
    "\n",
    "# card_id ごとに month_diff の平均値を計算\n",
    "df_his_mean = df_his.groupby('card_id').agg({'month_diff': 'mean'}).astype('float32').reset_index()\n",
    "\n",
    "# killer_feature を作成\n",
    "killer_feature = pd.merge(df_his_mean, first_last_dates, on='card_id', how='inner')\n",
    "killer_feature['kil_feature'] = killer_feature['month_diff'] / killer_feature['transaction_days']\n",
    "killer_feature['kil_feature'] = killer_feature['kil_feature'].astype('float32')\n",
    "\n",
    "# 不要な列を削除\n",
    "killer_feature.drop(columns=['first_purchase_date', 'month_diff', 'last_purchase_date', 'transaction_days'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train = pd.merge(train, month_diff, on='card_id', how='left')\n",
    "test = pd.merge(test, month_diff, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, df_last_purchase, on='card_id', how='left')\n",
    "test = pd.merge(test, df_last_purchase, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, max_amount, on='card_id', how='left')\n",
    "test = pd.merge(test, max_amount, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, diff_amount, on='card_id', how='left')\n",
    "test = pd.merge(test, diff_amount, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, killer_feature, on='card_id', how='left')\n",
    "test = pd.merge(test, killer_feature, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240622_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240622_test.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = read_data('../data/processed/processed20240622_train.csv')\n",
    "test = read_data('../data/processed/processed20240622_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"mean\"を含むカラムの欠損値をそのカラムの最大値で埋める\n",
    "mean_cols = [col for col in train.columns if \"mean\" in col]\n",
    "for col in mean_cols:\n",
    "    train[col] = train[col].fillna(train[col].mean())\n",
    "    test[col] = test[col].fillna(test[col].mean())\n",
    "\n",
    "# \"min\"を含むカラムの欠損値をそのカラムの最小値で埋める  \n",
    "min_cols = [col for col in train.columns if \"min\" in col]\n",
    "for col in min_cols:\n",
    "    train[col] = train[col].fillna(train[col].min())\n",
    "    test[col] = test[col].fillna(test[col].min())\n",
    "\n",
    "# \"max\"を含むカラムの欠損値をそのカラムの平均値で埋める\n",
    "max_cols = [col for col in train.columns if \"max\" in col]\n",
    "for col in max_cols:\n",
    "    train[col] = train[col].fillna(train[col].max())\n",
    "    test[col] = test[col].fillna(test[col].max())\n",
    "\n",
    "# \"nunique\"を含むカラムの欠損値をそのカラムの平均値で埋める\n",
    "nunique_cols = [col for col in train.columns if \"nunique\" in col]\n",
    "for col in nunique_cols:\n",
    "    train[col] = train[col].fillna(train[col].mean())\n",
    "    test[col] = test[col].fillna(test[col].mean())\n",
    "\n",
    "# \"ptp\"を含むカラムの欠損値をそのカラムの平均値で埋める\n",
    "ptp_cols = [col for col in train.columns if \"ptp\" in col]\n",
    "for col in ptp_cols:\n",
    "    train[col] = train[col].fillna(train[col].mean())\n",
    "    test[col] = test[col].fillna(test[col].mean())\n",
    "\n",
    "# \"count\"を含むカラムの欠損値を0で埋める\n",
    "count_cols = [col for col in train.columns if \"count\" in col]\n",
    "for col in count_cols:\n",
    "    train[col] = train[col].fillna(0)\n",
    "    test[col] = test[col].fillna(0)\n",
    "\n",
    "# \"ptp\"を含むカラムの欠損値をそのカラムの平均値で埋める\n",
    "sum_cols = [col for col in train.columns if \"sum\" in col]\n",
    "for col in sum_cols:\n",
    "    train[col] = train[col].fillna(train[col].mean())\n",
    "    test[col] = test[col].fillna(test[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"std\"を含むカラムの欠損値をそのカラムの平均値で埋める\n",
    "std_cols = [col for col in train.columns if \"std\" in col]\n",
    "for col in std_cols:\n",
    "    train[col] = train[col].fillna(train[col].mean())\n",
    "    test[col] = test[col].fillna(test[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexカラムの欠損値を-1で埋める\n",
    "train['index'] = train['index'].fillna(-1)\n",
    "test['index'] = test['index'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240624_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240624_test.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # データの読み込み\n",
    "# train = read_data('../data/processed/processed20240624_train.csv')\n",
    "# test = read_data('../data/processed/processed20240624_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各列のNaN値の数を取得\n",
    "null_counts = train.isnull().sum()\n",
    "\n",
    "# NaN値が少なくとも1つ含まれる列の位置を取得\n",
    "cols_with_nan = null_counts[null_counts > 0].index.tolist()\n",
    "\n",
    "# NaN値を含む列を表示\n",
    "print(train[cols_with_nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       first_active_month  elapsed_time\n",
      "0              2017-04-01         306.0\n",
      "1              2017-01-01         396.0\n",
      "2              2017-08-01         184.0\n",
      "3              2017-12-01          62.0\n",
      "4              2015-12-01         793.0\n",
      "...                   ...           ...\n",
      "123618         2017-10-01         123.0\n",
      "123619         2017-09-01         153.0\n",
      "123620         2016-09-01         518.0\n",
      "123621         2017-06-01         245.0\n",
      "123622         2016-10-01         488.0\n",
      "\n",
      "[123623 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 各列のNaN値の数を取得\n",
    "null_counts = test.isnull().sum()\n",
    "\n",
    "# NaN値が少なくとも1つ含まれる列の位置を取得\n",
    "cols_with_nan = null_counts[null_counts > 0].index.tolist()\n",
    "\n",
    "# NaN値を含む列を表示\n",
    "print(test[cols_with_nan])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
