{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02で前処理をしたデータの読み込みとモデルの学習を行うためのnotebookです。  \n",
    "ここで作成したモデルは **src/models/** フォルダに格納して推論の際に使うようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv('../data/processed/processed20240619_train.csv')\n",
    "test = pd.read_csv('../data/processed/processed20240619_test.csv')\n",
    "\n",
    "# 目的変数と説明変数の作成\n",
    "target = train['target']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month', 'target']]\n",
    "categorical_feats = ['feature_2', 'feature_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.7764\n",
      "[200]\tvalid_0's rmse: 3.72857\n",
      "[300]\tvalid_0's rmse: 3.70481\n",
      "[400]\tvalid_0's rmse: 3.6922\n",
      "[500]\tvalid_0's rmse: 3.6848\n",
      "[600]\tvalid_0's rmse: 3.68041\n",
      "[700]\tvalid_0's rmse: 3.67747\n",
      "[800]\tvalid_0's rmse: 3.67551\n",
      "[900]\tvalid_0's rmse: 3.67409\n",
      "[1000]\tvalid_0's rmse: 3.67305\n",
      "[1100]\tvalid_0's rmse: 3.67235\n",
      "[1200]\tvalid_0's rmse: 3.67201\n",
      "[1300]\tvalid_0's rmse: 3.67126\n",
      "[1400]\tvalid_0's rmse: 3.67107\n",
      "[1500]\tvalid_0's rmse: 3.67094\n",
      "[1600]\tvalid_0's rmse: 3.67078\n",
      "[1700]\tvalid_0's rmse: 3.67061\n",
      "[1800]\tvalid_0's rmse: 3.6703\n",
      "[1900]\tvalid_0's rmse: 3.67052\n",
      "Early stopping, best iteration is:\n",
      "[1779]\tvalid_0's rmse: 3.67026\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.70514\n",
      "[200]\tvalid_0's rmse: 3.66213\n",
      "[300]\tvalid_0's rmse: 3.64103\n",
      "[400]\tvalid_0's rmse: 3.63048\n",
      "[500]\tvalid_0's rmse: 3.62498\n",
      "[600]\tvalid_0's rmse: 3.62146\n",
      "[700]\tvalid_0's rmse: 3.61909\n",
      "[800]\tvalid_0's rmse: 3.61759\n",
      "[900]\tvalid_0's rmse: 3.61677\n",
      "[1000]\tvalid_0's rmse: 3.61619\n",
      "[1100]\tvalid_0's rmse: 3.61551\n",
      "[1200]\tvalid_0's rmse: 3.61532\n",
      "[1300]\tvalid_0's rmse: 3.61482\n",
      "[1400]\tvalid_0's rmse: 3.61478\n",
      "[1500]\tvalid_0's rmse: 3.61453\n",
      "[1600]\tvalid_0's rmse: 3.61443\n",
      "[1700]\tvalid_0's rmse: 3.61439\n",
      "[1800]\tvalid_0's rmse: 3.61428\n",
      "[1900]\tvalid_0's rmse: 3.61419\n",
      "[2000]\tvalid_0's rmse: 3.61415\n",
      "Early stopping, best iteration is:\n",
      "[1854]\tvalid_0's rmse: 3.61401\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.68081\n",
      "[200]\tvalid_0's rmse: 3.63914\n",
      "[300]\tvalid_0's rmse: 3.61972\n",
      "[400]\tvalid_0's rmse: 3.61003\n",
      "[500]\tvalid_0's rmse: 3.60457\n",
      "[600]\tvalid_0's rmse: 3.60117\n",
      "[700]\tvalid_0's rmse: 3.59909\n",
      "[800]\tvalid_0's rmse: 3.59733\n",
      "[900]\tvalid_0's rmse: 3.59634\n",
      "[1000]\tvalid_0's rmse: 3.59571\n",
      "[1100]\tvalid_0's rmse: 3.59519\n",
      "[1200]\tvalid_0's rmse: 3.59466\n",
      "[1300]\tvalid_0's rmse: 3.59433\n",
      "[1400]\tvalid_0's rmse: 3.59414\n",
      "[1500]\tvalid_0's rmse: 3.59413\n",
      "[1600]\tvalid_0's rmse: 3.59451\n",
      "Early stopping, best iteration is:\n",
      "[1490]\tvalid_0's rmse: 3.59401\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.87942\n",
      "[200]\tvalid_0's rmse: 3.83232\n",
      "[300]\tvalid_0's rmse: 3.8091\n",
      "[400]\tvalid_0's rmse: 3.79739\n",
      "[500]\tvalid_0's rmse: 3.79054\n",
      "[600]\tvalid_0's rmse: 3.78646\n",
      "[700]\tvalid_0's rmse: 3.78448\n",
      "[800]\tvalid_0's rmse: 3.78321\n",
      "[900]\tvalid_0's rmse: 3.7822\n",
      "[1000]\tvalid_0's rmse: 3.7817\n",
      "[1100]\tvalid_0's rmse: 3.78129\n",
      "[1200]\tvalid_0's rmse: 3.78104\n",
      "[1300]\tvalid_0's rmse: 3.78091\n",
      "[1400]\tvalid_0's rmse: 3.7808\n",
      "[1500]\tvalid_0's rmse: 3.78092\n",
      "Early stopping, best iteration is:\n",
      "[1356]\tvalid_0's rmse: 3.78063\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.694\n",
      "[200]\tvalid_0's rmse: 3.65278\n",
      "[300]\tvalid_0's rmse: 3.63425\n",
      "[400]\tvalid_0's rmse: 3.6251\n",
      "[500]\tvalid_0's rmse: 3.61998\n",
      "[600]\tvalid_0's rmse: 3.61721\n",
      "[700]\tvalid_0's rmse: 3.61543\n",
      "[800]\tvalid_0's rmse: 3.61455\n",
      "[900]\tvalid_0's rmse: 3.614\n",
      "[1000]\tvalid_0's rmse: 3.61338\n",
      "[1100]\tvalid_0's rmse: 3.61329\n",
      "[1200]\tvalid_0's rmse: 3.61343\n",
      "[1300]\tvalid_0's rmse: 3.6136\n",
      "Early stopping, best iteration is:\n",
      "[1161]\tvalid_0's rmse: 3.6131\n",
      "CV score: 3.65503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "# データの読み込み\n",
    "train = pd.read_csv('../data/processed/processed20240620_train.csv')\n",
    "test = pd.read_csv('../data/processed/processed20240620_test.csv')\n",
    "\n",
    "# 目的変数と説明変数の作成\n",
    "target = train['target']\n",
    "features = [c for c in train.columns if c not in ['card_id', 'first_active_month', 'target']]\n",
    "categorical_feats = []\n",
    "\n",
    "# KFoldで5分割して学習\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "param = {'num_leaves': 111,\n",
    "         'min_data_in_leaf': 149, \n",
    "         'objective':'regression',\n",
    "         'max_depth': 9,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7522,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7083 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.2634,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(f\"Fold {fold_+1}/5\")\n",
    "    \n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features],\n",
    "                           label=target.iloc[trn_idx],\n",
    "                           categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features],\n",
    "                           label=target.iloc[val_idx],\n",
    "                           categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(params=param,\n",
    "                    train_set=trn_data,\n",
    "                    num_boost_round=num_round,\n",
    "                    valid_sets=[val_data],\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=200),\n",
    "                               lgb.log_evaluation(100)])\n",
    "\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # モデルを保存\n",
    "    with open(f'../src/models/model_fold_{fold_}.pkl', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "\n",
    "print(f\"CV score: {mean_squared_error(oof, target)**0.5:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの予測\n",
    "for fold_ in range(5):\n",
    "    with open(f'../src/models/model_fold_{fold_}.pkl', 'rb') as f:\n",
    "        clf = pickle.load(f)\n",
    "    fold_predictions = clf.predict(test[features])\n",
    "    predictions += fold_predictions\n",
    "\n",
    "# 平均化\n",
    "predictions /= 5\n",
    "\n",
    "# 提出用のCSVファイルを作成\n",
    "sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submit_original_lightGBM.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
