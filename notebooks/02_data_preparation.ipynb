{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み込みと前処理を行うためのnotebookです。  \n",
    "モデルの学習と予測にはここで処理をかけたデータを利用するようにして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lifetimes import BetaGeoFitter, GammaGammaFitter\n",
    "from lifetimes.utils import summary_data_from_transaction_data\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def binarize(df):\n",
    "    \"\"\"\n",
    "    指定された列を二値化する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        二値化対象のデータフレーム。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        二値化されたデータフレーム。\n",
    "    \"\"\"\n",
    "\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y': 1, 'N': 0})\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_data(input_file):\n",
    "    \"\"\"\n",
    "    指定されたファイルからデータを読み込み、前処理を行う。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_file : str\n",
    "        読み込むデータファイルのパス。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        前処理されたデータフレーム。\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['elapsed_time'] = (pd.Timestamp('2018-02-01') - df['first_active_month']).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data('../data/row/train.csv')\n",
    "test = read_data('../data/row/test.csv')\n",
    "\n",
    "new_transactions = pd.read_csv('../data/row/new_merchant_transactions.csv',\n",
    "                               parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = pd.read_csv('../data/row/historical_transactions.csv',\n",
    "                                      parse_dates=['purchase_date'])\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_month_diff(transactions):\n",
    "    \"\"\"\n",
    "    purchase_dateとmonth_lagを基にmonth_diffを計算する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        month_diff列が追加されたデータフレーム。\n",
    "    \"\"\"\n",
    "    current_date = pd.Timestamp(datetime.datetime.today())\n",
    "    transactions['month_diff'] = ((current_date - transactions['purchase_date']).dt.days) // 30\n",
    "    transactions['month_diff'] += transactions['month_lag']\n",
    "    return transactions\n",
    "\n",
    "\n",
    "def encode_categorical_columns(df, columns):\n",
    "    \"\"\"\n",
    "    指定されたカテゴリカル列をワンホットエンコーディングする。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        エンコード対象のデータフレーム。\n",
    "    columns : list of str\n",
    "        エンコードするカテゴリカル列のリスト。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        ワンホットエンコードされたデータフレーム。\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=columns)\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    データフレームのメモリ使用量を減らす。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        メモリ使用量を削減したいデータフレーム。\n",
    "    verbose : bool, optional\n",
    "        メモリ使用量の削減結果を出力するかどうか（デフォルトは True）。\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        メモリ使用量が削減されたデータフレーム。\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def aggregate_transactions(history):\n",
    "    \"\"\"\n",
    "    取引データを集計する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    history.loc[:, 'purchase_date'] = pd.DatetimeIndex(history['purchase_date']).astype(np.int64) * 1e-9\n",
    "    \n",
    "    agg_func = {\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        'category_2_1.0': ['mean'],\n",
    "        'category_2_2.0': ['mean'],\n",
    "        'category_2_3.0': ['mean'],\n",
    "        'category_2_4.0': ['mean'],\n",
    "        'category_2_5.0': ['mean'],\n",
    "        'category_3_A': ['mean'],\n",
    "        'category_3_B': ['mean'],\n",
    "        'category_3_C': ['mean'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'state_id': ['nunique'],\n",
    "        'city_id': ['nunique'],\n",
    "        'subsector_id': ['nunique'],\n",
    "        'purchase_amount': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'installments': ['sum', 'mean', 'max', 'min', 'std'],\n",
    "        'purchase_month': ['mean', 'max', 'min', 'std'],\n",
    "        'purchase_date': [np.ptp, 'min', 'max'],\n",
    "        'month_lag': ['mean', 'max', 'min', 'std'],\n",
    "        'month_diff': ['mean']\n",
    "    }\n",
    "    \n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "    \n",
    "    return agg_history\n",
    "\n",
    "\n",
    "def aggregate_per_month(history):\n",
    "    \"\"\"\n",
    "    月ごとの取引データを集計する。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        月ごとに集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    grouped = history.groupby(['card_id', 'month_lag'])\n",
    "\n",
    "    agg_func = {\n",
    "        'purchase_amount': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "        'installments': ['count', 'sum', 'mean', 'min', 'max', 'std'],\n",
    "    }\n",
    "\n",
    "    intermediate_group = grouped.agg(agg_func)\n",
    "    intermediate_group.columns = ['_'.join(col).strip() for col in intermediate_group.columns.values]\n",
    "    intermediate_group.reset_index(inplace=True)\n",
    "\n",
    "    final_group = intermediate_group.groupby('card_id').agg(['mean', 'std'])\n",
    "    final_group.columns = ['_'.join(col).strip() for col in final_group.columns.values]\n",
    "    final_group.reset_index(inplace=True)\n",
    "    \n",
    "    return final_group\n",
    "\n",
    "\n",
    "def successive_aggregates(df, field1, field2):\n",
    "    \"\"\"\n",
    "    指定されたフィールドを基に連続集計を行う。\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        取引データのデータフレーム。\n",
    "    field1 : str\n",
    "        集計の基準となるフィールド。\n",
    "    field2 : str\n",
    "        集計されるフィールド。\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        連続集計されたデータフレーム。\n",
    "    \"\"\"\n",
    "    t = df.groupby(['card_id', field1])[field2].mean()\n",
    "    u = pd.DataFrame(t).reset_index().groupby('card_id')[field2].agg(['mean', 'min', 'max', 'std'])\n",
    "    u.columns = [field1 + '_' + field2 + '_' + col for col in u.columns.values]\n",
    "    u.reset_index(inplace=True)\n",
    "    return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1332.66 Mb (57.1% reduction)\n",
      "Mem. usage decreased to 86.12 Mb (58.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "# データ準備\n",
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])\n",
    "\n",
    "# 月の差を計算\n",
    "historical_transactions = calculate_month_diff(historical_transactions)\n",
    "new_transactions = calculate_month_diff(new_transactions)\n",
    "\n",
    "# カテゴリカル列をワンホットエンコーディング\n",
    "historical_transactions = encode_categorical_columns(historical_transactions, ['category_2', 'category_3'])\n",
    "new_transactions = encode_categorical_columns(new_transactions, ['category_2', 'category_3'])\n",
    "\n",
    "# メモリ使用量の削減\n",
    "historical_transactions = reduce_mem_usage(historical_transactions)\n",
    "new_transactions = reduce_mem_usage(new_transactions)\n",
    "\n",
    "# authorized_flagの平均を計算\n",
    "agg_fun = {'authorized_flag': ['mean']}\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "# authorized_flagに基づいてデータを分割\n",
    "authorized_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]\n",
    "historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 0]\n",
    "\n",
    "# purchase_month列を追加\n",
    "historical_transactions['purchase_month'] = historical_transactions['purchase_date'].dt.month\n",
    "authorized_transactions['purchase_month'] = authorized_transactions['purchase_date'].dt.month\n",
    "new_transactions['purchase_month'] = new_transactions['purchase_date'].dt.month\n",
    "\n",
    "# データの集計\n",
    "history = aggregate_transactions(historical_transactions)\n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "\n",
    "authorized = aggregate_transactions(authorized_transactions)\n",
    "authorized.columns = ['auth_' + c if c != 'card_id' else c for c in authorized.columns]\n",
    "\n",
    "new = aggregate_transactions(new_transactions)\n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "\n",
    "# 月ごとのデータの集計\n",
    "final_group = aggregate_per_month(authorized_transactions)\n",
    "\n",
    "# 連続集計\n",
    "additional_fields = successive_aggregates(new_transactions, 'category_1', 'purchase_amount')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'installments', 'purchase_amount'), on='card_id', how='left')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'city_id', 'purchase_amount'), on='card_id', how='left')\n",
    "additional_fields = additional_fields.merge(successive_aggregates(new_transactions, 'category_1', 'installments'), on='card_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTVの計算\n",
    "# 1. CSVファイルの読み込みと特定のカラムの選択\n",
    "n_merc = pd.read_csv('../data/row/new_merchant_transactions.csv', usecols = ['card_id', 'purchase_amount', 'purchase_date'])\n",
    "h_merc = pd.read_csv('../data/row/historical_transactions.csv', usecols = ['card_id', 'purchase_amount', 'purchase_date'])\n",
    "merc = pd.concat([n_merc, h_merc], axis = 0)\n",
    "\n",
    "# 2. 購入額の変換\n",
    "n_merc['transformed'] = (n_merc['purchase_amount'] / 0.00001503)\n",
    "n_merc['transformed'] = n_merc['transformed'] - n_merc['transformed'].min()\n",
    "n_merc['transformed'] = np.log1p(n_merc['transformed'])\n",
    "\n",
    "h_merc['transformed'] = (h_merc['purchase_amount'] / 0.00001503)\n",
    "h_merc['transformed'] = h_merc['transformed'] - h_merc['transformed'].min()\n",
    "h_merc['transformed'] = np.log1p(h_merc['transformed'])\n",
    "\n",
    "merc['transformed'] = (merc['purchase_amount'] / 0.00001503)\n",
    "merc['transformed'] = merc['transformed'] - merc['transformed'].min()\n",
    "merc['transformed'] = np.log1p(merc['transformed'])\n",
    "\n",
    "# 顧客ごとの取引履歴の集計\n",
    "n_customer_transactions = n_merc.groupby('card_id').agg({\n",
    "    'transformed': ['sum', 'count'],\n",
    "    'purchase_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "h_customer_transactions = h_merc.groupby('card_id').agg({\n",
    "    'transformed': ['sum', 'count'],\n",
    "    'purchase_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "m_customer_transactions = merc.groupby('card_id').agg({\n",
    "    'transformed': ['sum', 'count'],\n",
    "    'purchase_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# カラム名をフラットにする\n",
    "n_customer_transactions.columns = ['card_id', 'total_purchase_amount', 'transaction_count', 'first_purchase_date', 'last_purchase_date']\n",
    "h_customer_transactions.columns = ['card_id', 'total_purchase_amount', 'transaction_count', 'first_purchase_date', 'last_purchase_date']\n",
    "m_customer_transactions.columns = ['card_id', 'total_purchase_amount', 'transaction_count', 'first_purchase_date', 'last_purchase_date']\n",
    "\n",
    "# 日付をdatetime型に変換\n",
    "n_customer_transactions['first_purchase_date'] = pd.to_datetime(n_customer_transactions['first_purchase_date'])\n",
    "n_customer_transactions['last_purchase_date'] = pd.to_datetime(n_customer_transactions['last_purchase_date'])\n",
    "\n",
    "h_customer_transactions['first_purchase_date'] = pd.to_datetime(h_customer_transactions['first_purchase_date'])\n",
    "h_customer_transactions['last_purchase_date'] = pd.to_datetime(h_customer_transactions['last_purchase_date'])\n",
    "\n",
    "m_customer_transactions['first_purchase_date'] = pd.to_datetime(m_customer_transactions['first_purchase_date'])\n",
    "m_customer_transactions['last_purchase_date'] = pd.to_datetime(m_customer_transactions['last_purchase_date'])\n",
    "\n",
    "# 継続購買期間（日数）の計算\n",
    "n_customer_transactions['lifetime_days'] = (n_customer_transactions['last_purchase_date'] - n_customer_transactions['first_purchase_date']).dt.days\n",
    "h_customer_transactions['lifetime_days'] = (h_customer_transactions['last_purchase_date'] - h_customer_transactions['first_purchase_date']).dt.days\n",
    "m_customer_transactions['lifetime_days'] = (m_customer_transactions['last_purchase_date'] - m_customer_transactions['first_purchase_date']).dt.days\n",
    "\n",
    "# 平均購入価格の計算\n",
    "n_customer_transactions['avg_purchase_value'] = n_customer_transactions['total_purchase_amount'] / n_customer_transactions['transaction_count']\n",
    "h_customer_transactions['avg_purchase_value'] = h_customer_transactions['total_purchase_amount'] / h_customer_transactions['transaction_count']\n",
    "m_customer_transactions['avg_purchase_value'] = m_customer_transactions['total_purchase_amount'] / m_customer_transactions['transaction_count']\n",
    "\n",
    "# 平均購入頻度の計算（1年間を仮定）\n",
    "n_customer_transactions['avg_purchase_frequency'] = n_customer_transactions['transaction_count'] / (n_customer_transactions['lifetime_days'] / 365)\n",
    "h_customer_transactions['avg_purchase_frequency'] = h_customer_transactions['transaction_count'] / (h_customer_transactions['lifetime_days'] / 365)\n",
    "m_customer_transactions['avg_purchase_frequency'] = m_customer_transactions['transaction_count'] / (m_customer_transactions['lifetime_days'] / 365)\n",
    "\n",
    "# LTVの計算\n",
    "n_customer_transactions['new_LTV'] = n_customer_transactions['avg_purchase_value'] * n_customer_transactions['avg_purchase_frequency'] * n_customer_transactions['lifetime_days']\n",
    "h_customer_transactions['hist_LTV'] = h_customer_transactions['avg_purchase_value'] * h_customer_transactions['avg_purchase_frequency'] * h_customer_transactions['lifetime_days']\n",
    "m_customer_transactions['total_LTV'] = m_customer_transactions['avg_purchase_value'] * m_customer_transactions['avg_purchase_frequency'] * m_customer_transactions['lifetime_days']\n",
    "\n",
    "n_df_ltv = n_customer_transactions[['card_id', 'new_LTV']]\n",
    "h_df_ltv = h_customer_transactions[['card_id', 'hist_LTV']]\n",
    "m_df_ltv = m_customer_transactions[['card_id', 'total_LTV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLVの計算\n",
    "from lifetimes import BetaGeoFitter, GammaGammaFitter\n",
    "from lifetimes.utils import summary_data_from_transaction_data\n",
    "\n",
    "# CSVファイルの読み込みと特定のカラムの選択\n",
    "n_merc = pd.read_csv('../data/row/new_merchant_transactions.csv', usecols = ['card_id', 'purchase_amount', 'purchase_date'])\n",
    "h_merc = pd.read_csv('../data/row/historical_transactions.csv', usecols = ['card_id', 'purchase_amount', 'purchase_date'])\n",
    "merc = pd.concat([n_merc, h_merc], axis = 0)\n",
    "\n",
    "#　購入額の変換\n",
    "n_merc['transformed'] = (n_merc['purchase_amount'] / 0.00001503)\n",
    "n_merc['transformed'] = n_merc['transformed'] - n_merc['transformed'].min()\n",
    "n_merc['transformed'] = np.log1p(n_merc['transformed'])\n",
    "\n",
    "h_merc['transformed'] = (h_merc['purchase_amount'] / 0.00001503)\n",
    "h_merc['transformed'] = h_merc['transformed'] - h_merc['transformed'].min()\n",
    "h_merc['transformed'] = np.log1p(h_merc['transformed'])\n",
    "\n",
    "merc['transformed'] = (merc['purchase_amount'] / 0.00001503)\n",
    "merc['transformed'] = merc['transformed'] - merc['transformed'].min()\n",
    "merc['transformed'] = np.log1p(merc['transformed'])\n",
    "\n",
    "# 日付型に変換\n",
    "n_merc['purchase_date'] = pd.to_datetime(n_merc['purchase_date'])\n",
    "h_merc['purchase_date'] = pd.to_datetime(h_merc['purchase_date'])\n",
    "merc['purchase_date'] = pd.to_datetime(merc['purchase_date'])\n",
    "\n",
    "# RFMテーブルの作成\n",
    "n_rfm_summary = summary_data_from_transaction_data(n_merc, 'card_id', 'purchase_date', monetary_value_col = 'transformed', observation_period_end = n_merc['purchase_date'].max())\n",
    "h_rfm_summary = summary_data_from_transaction_data(h_merc, 'card_id', 'purchase_date', monetary_value_col = 'transformed', observation_period_end = h_merc['purchase_date'].max())\n",
    "m_rfm_summary = summary_data_from_transaction_data(merc, 'card_id', 'purchase_date', monetary_value_col = 'transformed', observation_period_end = merc['purchase_date'].max())\n",
    "\n",
    "# カラム名をフラットにする\n",
    "n_rfm_summary.columns = ['new_frequency_rfm', 'new_recency_rfm', 'new_T_rfm', 'new_monetary_value']\n",
    "h_rfm_summary.columns = ['hist_frequency_rfm', 'hist_recency_rfm', 'hist_T_rfm', 'hist_monetary_value']\n",
    "m_rfm_summary.columns = ['total_frequency_rfm', 'total_recency_rfm', 'total_T_rfm', 'total_monetary_value']\n",
    "\n",
    "n_rfm_summary = n_rfm_summary[n_rfm_summary['new_monetary_value'] > 0]\n",
    "\n",
    "# BG/NBDモデルの適用（ペナルティを追加）\n",
    "n_bgf = BetaGeoFitter(penalizer_coef = 1)\n",
    "n_bgf.fit(n_rfm_summary['new_frequency_rfm'], n_rfm_summary['new_recency_rfm'], n_rfm_summary['new_T_rfm'])\n",
    "\n",
    "h_bgf = BetaGeoFitter(penalizer_coef = 1)\n",
    "h_bgf.fit(h_rfm_summary['hist_frequency_rfm'], h_rfm_summary['hist_recency_rfm'], h_rfm_summary['hist_T_rfm'])\n",
    "\n",
    "m_bgf = BetaGeoFitter(penalizer_coef = 1)\n",
    "m_bgf.fit(m_rfm_summary['total_frequency_rfm'], m_rfm_summary['total_recency_rfm'], m_rfm_summary['total_T_rfm'])\n",
    "\n",
    "# 顧客ごとの予測購入回数\n",
    "n_rfm_summary['new_predicted_purchases'] = n_bgf.conditional_expected_number_of_purchases_up_to_time(12, n_rfm_summary['new_frequency_rfm'], n_rfm_summary['new_recency_rfm'], n_rfm_summary['new_T_rfm'])\n",
    "h_rfm_summary['hist_predicted_purchases'] = h_bgf.conditional_expected_number_of_purchases_up_to_time(12, h_rfm_summary['hist_frequency_rfm'], h_rfm_summary['hist_recency_rfm'], h_rfm_summary['hist_T_rfm'])\n",
    "m_rfm_summary['total_predicted_purchases'] = m_bgf.conditional_expected_number_of_purchases_up_to_time(15, m_rfm_summary['total_frequency_rfm'], m_rfm_summary['total_recency_rfm'], m_rfm_summary['total_T_rfm'])\n",
    "\n",
    "# Gamma-Gammaモデルの適用\n",
    "n_ggf = GammaGammaFitter(penalizer_coef = 1)\n",
    "n_ggf.fit(n_rfm_summary['new_frequency_rfm'], n_rfm_summary['new_monetary_value'])\n",
    "\n",
    "h_ggf = GammaGammaFitter(penalizer_coef = 1)\n",
    "h_ggf.fit(h_rfm_summary['hist_frequency_rfm'], h_rfm_summary['hist_monetary_value'])\n",
    "\n",
    "m_ggf = GammaGammaFitter(penalizer_coef = 1)\n",
    "m_ggf.fit(m_rfm_summary['total_frequency_rfm'], m_rfm_summary['total_monetary_value'])\n",
    "\n",
    "# 顧客ごとの予測収益\n",
    "n_rfm_summary['new_predicted_monetary_value'] = n_ggf.conditional_expected_average_profit(n_rfm_summary['new_frequency_rfm'], n_rfm_summary['new_monetary_value'])\n",
    "h_rfm_summary['hist_predicted_monetary_value'] = h_ggf.conditional_expected_average_profit(h_rfm_summary['hist_frequency_rfm'], h_rfm_summary['hist_monetary_value'])\n",
    "m_rfm_summary['total_predicted_monetary_value'] = m_ggf.conditional_expected_average_profit(m_rfm_summary['total_frequency_rfm'], m_rfm_summary['total_monetary_value'])\n",
    "\n",
    "# CLVの計算\n",
    "n_rfm_summary['new_clv'] = n_ggf.customer_lifetime_value(\n",
    "    n_bgf,\n",
    "    n_rfm_summary['new_frequency_rfm'],\n",
    "    n_rfm_summary['new_recency_rfm'],\n",
    "    n_rfm_summary['new_T_rfm'],\n",
    "    n_rfm_summary['new_monetary_value'],\n",
    "    time=12, # 12ヶ月の期間でCLVを予測\n",
    "    discount_rate=0.01\n",
    ")\n",
    "\n",
    "h_rfm_summary['hist_clv'] = h_ggf.customer_lifetime_value(\n",
    "    h_bgf,\n",
    "    h_rfm_summary['hist_frequency_rfm'],\n",
    "    h_rfm_summary['hist_recency_rfm'],\n",
    "    h_rfm_summary['hist_T_rfm'],\n",
    "    h_rfm_summary['hist_monetary_value'],\n",
    "    time=12, # 12ヶ月の期間でCLVを予測\n",
    "    discount_rate=0.01\n",
    ")\n",
    "\n",
    "m_rfm_summary['total_clv'] = m_ggf.customer_lifetime_value(\n",
    "    m_bgf,\n",
    "    m_rfm_summary['total_frequency_rfm'],\n",
    "    m_rfm_summary['total_recency_rfm'],\n",
    "    m_rfm_summary['total_T_rfm'],\n",
    "    m_rfm_summary['total_monetary_value'],\n",
    "    time=15, # 12ヶ月の期間でCLVを予測\n",
    "    discount_rate=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churnの計算\n",
    "# 1. CSVファイルの読み込みと特定のカラムの選択\n",
    "n_merc = pd.read_csv('../data/row/new_merchant_transactions.csv', usecols = ['card_id', 'purchase_amount', 'purchase_date'])\n",
    "h_merc = pd.read_csv('../data/row/historical_transactions.csv', usecols = ['card_id', 'purchase_amount', 'purchase_date'])\n",
    "merc = pd.concat([n_merc, h_merc], axis = 0)\n",
    "\n",
    "n_merc['purchase_date'] = pd.to_datetime(n_merc['purchase_date'])\n",
    "h_merc['purchase_date'] = pd.to_datetime(h_merc['purchase_date'])\n",
    "merc['purchase_date'] = pd.to_datetime(merc['purchase_date'])\n",
    "\n",
    "# 5. 購入額の変換\n",
    "n_merc['transformed'] = (n_merc['purchase_amount'] / 0.00001503)\n",
    "n_merc['transformed'] = n_merc['transformed'] - n_merc['transformed'].min()\n",
    "n_merc['transformed'] = np.log1p(n_merc['transformed'])\n",
    "\n",
    "h_merc['transformed'] = (h_merc['purchase_amount'] / 0.00001503)\n",
    "h_merc['transformed'] = h_merc['transformed'] - h_merc['transformed'].min()\n",
    "h_merc['transformed'] = np.log1p(h_merc['transformed'])\n",
    "\n",
    "merc['transformed'] = (merc['purchase_amount'] / 0.00001503)\n",
    "merc['transformed'] = merc['transformed'] - merc['transformed'].min()\n",
    "merc['transformed'] = np.log1p(merc['transformed'])\n",
    "\n",
    "# n_merc\n",
    "# 特徴量エンジニアリング\n",
    "n_merc['year_month'] = n_merc['purchase_date'].dt.to_period('M')\n",
    "agg_func = {\n",
    "    'transformed': ['sum', 'mean', 'max', 'min'],\n",
    "    'purchase_date': ['count']\n",
    "}\n",
    "n_merc_customer_features = n_merc.groupby('card_id').agg(agg_func).reset_index()\n",
    "n_merc_customer_features.columns = ['card_id', 'total_purchase_amount', 'average_purchase_amount', 'max_purchase_amount', 'min_purchase_amount', 'purchase_count']\n",
    "\n",
    "# 最後の購入日を特徴量として追加\n",
    "n_merc_last_purchase_date = n_merc.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "n_merc_last_purchase_date.columns = ['card_id', 'last_purchase_date']\n",
    "\n",
    "# 現在の日付を設定（最新の取引日＋1を現在の日付と仮定）\n",
    "n_merc_current_date = n_merc['purchase_date'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# 最後の購入日からの日数を計算\n",
    "n_merc_customer_features = n_merc_customer_features.merge(n_merc_last_purchase_date, on = 'card_id')\n",
    "n_merc_customer_features['days_since_last_purchase'] = (n_merc_current_date - n_merc_customer_features['last_purchase_date']).dt.days\n",
    "\n",
    "# ターゲット変数（チャーンかどうか）を作成\n",
    "# ここでは30日間購入がない顧客をチャーンと仮定\n",
    "n_merc_customer_features['churn'] = (n_merc_customer_features['days_since_last_purchase'] > 30).astype(int)\n",
    "\n",
    "# h_merc\n",
    "# 特徴量エンジニアリング\n",
    "h_merc['year_month'] = h_merc['purchase_date'].dt.to_period('M')\n",
    "agg_func = {\n",
    "    'purchase_amount': ['sum', 'mean', 'max', 'min'],\n",
    "    'purchase_date': ['count']\n",
    "}\n",
    "h_merc_customer_features = h_merc.groupby('card_id').agg(agg_func).reset_index()\n",
    "h_merc_customer_features.columns = ['card_id', 'total_purchase_amount', 'average_purchase_amount', 'max_purchase_amount', 'min_purchase_amount', 'purchase_count']\n",
    "\n",
    "# 最後の購入日を特徴量として追加\n",
    "h_merc_last_purchase_date = h_merc.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "h_merc_last_purchase_date.columns = ['card_id', 'last_purchase_date']\n",
    "\n",
    "# 現在の日付を設定（最新の取引日＋1を現在の日付と仮定）\n",
    "h_merc_current_date = h_merc['purchase_date'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# 最後の購入日からの日数を計算\n",
    "h_merc_customer_features = h_merc_customer_features.merge(h_merc_last_purchase_date, on = 'card_id')\n",
    "h_merc_customer_features['days_since_last_purchase'] = (h_merc_current_date - h_merc_customer_features['last_purchase_date']).dt.days\n",
    "\n",
    "# ターゲット変数（チャーンかどうか）を作成\n",
    "# ここでは30日間購入がない顧客をチャーンと仮定\n",
    "h_merc_customer_features['churn'] = (h_merc_customer_features['days_since_last_purchase'] > 30).astype(int)\n",
    "\n",
    "# merc\n",
    "# 特徴量エンジニアリング\n",
    "merc['year_month'] = merc['purchase_date'].dt.to_period('M')\n",
    "agg_func = {\n",
    "    'purchase_amount': ['sum', 'mean', 'max', 'min'],\n",
    "    'purchase_date': ['count']\n",
    "}\n",
    "merc_customer_features = merc.groupby('card_id').agg(agg_func).reset_index()\n",
    "merc_customer_features.columns = ['card_id', 'total_purchase_amount', 'average_purchase_amount', 'max_purchase_amount', 'min_purchase_amount', 'purchase_count']\n",
    "\n",
    "# 最後の購入日を特徴量として追加\n",
    "merc_last_purchase_date = merc.groupby('card_id')['purchase_date'].max().reset_index()\n",
    "merc_last_purchase_date.columns = ['card_id', 'last_purchase_date']\n",
    "\n",
    "# 現在の日付を設定（最新の取引日＋1を現在の日付と仮定）\n",
    "merc_current_date = merc['purchase_date'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# 最後の購入日からの日数を計算\n",
    "merc_customer_features = merc_customer_features.merge(merc_last_purchase_date, on = 'card_id')\n",
    "merc_customer_features['days_since_last_purchase'] = (merc_current_date - merc_customer_features['last_purchase_date']).dt.days\n",
    "\n",
    "# ターゲット変数（チャーンかどうか）を作成\n",
    "# ここでは30日間購入がない顧客をチャーンと仮定\n",
    "merc_customer_features['churn'] = (merc_customer_features['days_since_last_purchase'] > 30).astype(int)\n",
    "\n",
    "# n_merch\n",
    "# 特徴量とターゲットの分割\n",
    "n_merc_features = ['total_purchase_amount', 'average_purchase_amount', 'max_purchase_amount', 'min_purchase_amount', 'purchase_count', 'days_since_last_purchase']\n",
    "n_merc_X = n_merc_customer_features[n_merc_features]\n",
    "n_merc_y = n_merc_customer_features['churn']\n",
    "\n",
    "# 訓練データとテストデータに分割\n",
    "n_merc_X_train, n_merc_X_test, n_merc_y_train, n_merc_y_test = train_test_split(n_merc_X, n_merc_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルの訓練\n",
    "n_merc_model = RandomForestClassifier(random_state=42)\n",
    "n_merc_model.fit(n_merc_X_train, n_merc_y_train)\n",
    "\n",
    "# 予測\n",
    "n_merc_y_pred = n_merc_model.predict(n_merc_X_test)\n",
    "\n",
    "# h_merch\n",
    "# 特徴量とターゲットの分割\n",
    "h_merc_features = ['total_purchase_amount', 'average_purchase_amount', 'max_purchase_amount', 'min_purchase_amount', 'purchase_count', 'days_since_last_purchase']\n",
    "h_merc_X = h_merc_customer_features[h_merc_features]\n",
    "h_merc_y = h_merc_customer_features['churn']\n",
    "\n",
    "# 訓練データとテストデータに分割\n",
    "h_merc_X_train, h_merc_X_test, h_merc_y_train, h_merc_y_test = train_test_split(h_merc_X, h_merc_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルの訓練\n",
    "h_merc_model = RandomForestClassifier(random_state=42)\n",
    "h_merc_model.fit(h_merc_X_train, h_merc_y_train)\n",
    "\n",
    "# 予測\n",
    "h_merc_y_pred = h_merc_model.predict(h_merc_X_test)\n",
    "\n",
    "# merch\n",
    "# 特徴量とターゲットの分割\n",
    "merc_features = ['total_purchase_amount', 'average_purchase_amount', 'max_purchase_amount', 'min_purchase_amount', 'purchase_count', 'days_since_last_purchase']\n",
    "merc_X = merc_customer_features[merc_features]\n",
    "merc_y = merc_customer_features['churn']\n",
    "\n",
    "# 訓練データとテストデータに分割\n",
    "merc_X_train, merc_X_test, merc_y_train, merc_y_test = train_test_split(merc_X, merc_y, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルの訓練\n",
    "merc_model = RandomForestClassifier(random_state=42)\n",
    "merc_model.fit(merc_X_train, merc_y_train)\n",
    "\n",
    "# 予測\n",
    "merc_y_pred = merc_model.predict(merc_X_test)\n",
    "\n",
    "n_merc_customer_features['new_predicted_churn'] = n_merc_model.predict(n_merc_X)\n",
    "h_merc_customer_features['hist_predicted_churn'] = h_merc_model.predict(h_merc_X)\n",
    "merc_customer_features['total_predicted_churn'] = merc_model.predict(merc_X)\n",
    "\n",
    "n_df_churn = n_merc_customer_features[['card_id', 'new_predicted_churn']]\n",
    "h_df_churn = h_merc_customer_features[['card_id', 'hist_predicted_churn']]\n",
    "m_df_churn = merc_customer_features[['card_id', 'total_predicted_churn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの結合\n",
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, authorized, on='card_id', how='left')\n",
    "test = pd.merge(test, authorized, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, final_group, on='card_id', how='left')\n",
    "test = pd.merge(test, final_group, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, additional_fields, on='card_id', how='left')\n",
    "test = pd.merge(test, additional_fields, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, n_df_ltv, on='card_id', how='left')\n",
    "test = pd.merge(test, n_df_ltv, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, h_df_ltv, on='card_id', how='left')\n",
    "test = pd.merge(test, h_df_ltv, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, m_df_ltv, on='card_id', how='left')\n",
    "test = pd.merge(test, m_df_ltv, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, n_rfm_summary, on='card_id', how='left')\n",
    "test = pd.merge(test, n_rfm_summary, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, h_rfm_summary, on='card_id', how='left')\n",
    "test = pd.merge(test, h_rfm_summary, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, m_rfm_summary, on='card_id', how='left')\n",
    "test = pd.merge(test, m_rfm_summary, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, n_df_churn, on='card_id', how='left')\n",
    "test = pd.merge(test, n_df_churn, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, h_df_churn, on='card_id', how='left')\n",
    "test = pd.merge(test, h_df_churn, on='card_id', how='left')\n",
    "\n",
    "train = pd.merge(train, m_df_churn, on='card_id', how='left')\n",
    "test = pd.merge(test, m_df_churn, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理終了後のデータの保存\n",
    "- 基本的にモデルの学習・ハイパーパラメータチューニングを行う際にはここで作成した同じデータを使い回して下さい。\n",
    "- 適宜前処理を変更した場合はファイル名を変えるなどして管理して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの保存\n",
    "train.to_csv('../data/processed/processed20240614_train.csv',index=None)\n",
    "test.to_csv('../data/processed/processed20240614_test.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
